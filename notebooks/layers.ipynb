{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers import (\n",
    "    NumericalFeatureEmbedding,\n",
    "    CategoricalFeatureEmbedding, \n",
    "    FeatureEmbedding, \n",
    "    TransformerEncoder, \n",
    "    MLP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights shape:  (1, 2, 6)\n",
      "x shape:  (100, 2, 1)\n",
      "output shape:  (100, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_features = 2\n",
    "dim_token = 6\n",
    "\n",
    "x_num = np.random.random(size=(100, 2))\n",
    "\n",
    "d_sqrt_inv = 1 / np.sqrt(dim_token)\n",
    "\n",
    "# Learnable weights\n",
    "w = np.random.uniform(low=-d_sqrt_inv, high=d_sqrt_inv, size=(num_features,dim_token))\n",
    "b = np.random.uniform(low=-d_sqrt_inv, high=d_sqrt_inv, size=(num_features,dim_token))\n",
    "\n",
    "output = w[np.newaxis] *x_num[...,np.newaxis] + b\n",
    "\n",
    "print(\"weights shape: \",w[np.newaxis].shape)\n",
    "print(\"x shape: \",x_num[...,np.newaxis].shape)\n",
    "print(\"output shape: \",(w[np.newaxis] *x_num[...,np.newaxis]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "num_features = 10\n",
    "dim_token = 32\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=num_features, \n",
    "    n_informative=num_features, n_redundant=0, \n",
    "    n_repeated=0, n_classes=2, \n",
    "    n_clusters_per_class=2,\n",
    "    shuffle=True, random_state=123\n",
    ")\n",
    "\n",
    "ne = NumericalFeatureEmbedding(num_features=num_features,dim_token=dim_token)\n",
    "\n",
    "ne(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic MLP classification with NumericalFeatureEmbedding \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (100, 2)\n",
      "output shape:  (100, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "cardinalities = [5, 10, 20, 10,5]\n",
    "num_features = len(cardinalities)\n",
    "dim_token = 6\n",
    "\n",
    "x_cat = np.concatenate([np.random.randint(low=0,high=c,size=(100,1)) for c in cardinalities], axis=1)\n",
    "\n",
    "offsets = np.cumsum([0] + cardinalities[:-1], axis=0)\n",
    "\n",
    "total_tokens = sum(cardinalities)\n",
    "\n",
    "# # Learnable weights\n",
    "d_sqrt_inv = 1 / np.sqrt(dim_token)\n",
    "\n",
    "emb = keras.layers.Embedding(input_dim=total_tokens, output_dim=dim_token)\n",
    "b = np.random.uniform(low=-d_sqrt_inv, high=d_sqrt_inv, size=(num_features,dim_token))\n",
    "output = emb(x_cat + offsets) + b\n",
    "\n",
    "print(\"input shape: \",x_num.shape)\n",
    "print(\"output shape: \",output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 8, 32), dtype=float32, numpy=\n",
       "array([[[-0.21157132,  0.06224575, -0.16173288, ..., -0.21423268,\n",
       "         -0.12774879, -0.15862733],\n",
       "        [-0.09974983, -0.07074656, -0.06262894, ...,  0.08302263,\n",
       "          0.2019066 , -0.09884878],\n",
       "        [-0.15838726,  0.02515485, -0.07299703, ..., -0.26734942,\n",
       "         -0.06252657,  0.03538641],\n",
       "        ...,\n",
       "        [ 0.08510815,  0.21257526, -0.03557715, ..., -0.15214893,\n",
       "          0.12951714, -0.17795222],\n",
       "        [ 0.15064844,  0.27025256,  0.04708365, ...,  0.02033691,\n",
       "         -0.02297193,  0.05043186],\n",
       "        [ 0.10367307, -0.12014414, -0.26733568, ..., -0.068225  ,\n",
       "         -0.01493998,  0.04364815]],\n",
       "\n",
       "       [[-0.08266047,  0.23557323, -0.01562801, ..., -0.05817087,\n",
       "         -0.23796213,  0.05267194],\n",
       "        [-0.22358014,  0.01417179, -0.08427122, ..., -0.00529899,\n",
       "         -0.11553805, -0.02467071],\n",
       "        [-0.24210581,  0.16111772, -0.09392573, ...,  0.03025427,\n",
       "         -0.02894174,  0.10917954],\n",
       "        ...,\n",
       "        [ 0.08640543,  0.00583139,  0.01949579, ..., -0.05827793,\n",
       "         -0.0778814 , -0.08619381],\n",
       "        [-0.03329933,  0.20854585,  0.13450304, ...,  0.09730271,\n",
       "          0.05410257, -0.02801484],\n",
       "        [ 0.1987397 , -0.06898094, -0.13910331, ...,  0.12287518,\n",
       "         -0.3224453 ,  0.0381047 ]],\n",
       "\n",
       "       [[-0.08266047,  0.23557323, -0.01562801, ..., -0.05817087,\n",
       "         -0.23796213,  0.05267194],\n",
       "        [-0.09974983, -0.07074656, -0.06262894, ...,  0.08302263,\n",
       "          0.2019066 , -0.09884878],\n",
       "        [-0.1267902 ,  0.0338221 ,  0.12604904, ..., -0.14197128,\n",
       "          0.07020864,  0.03583831],\n",
       "        ...,\n",
       "        [ 0.16115336,  0.2414388 ,  0.28340217, ..., -0.1254485 ,\n",
       "         -0.05557825,  0.0772372 ],\n",
       "        [-0.05394665,  0.11074471,  0.09573121, ...,  0.09097642,\n",
       "         -0.14314553,  0.09651421],\n",
       "        [ 0.1987397 , -0.06898094, -0.13910331, ...,  0.12287518,\n",
       "         -0.3224453 ,  0.0381047 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.05747727,  0.03075695, -0.14488351, ..., -0.00120726,\n",
       "         -0.01127933,  0.01639323],\n",
       "        [-0.31020153, -0.12350768, -0.10527001, ...,  0.11336677,\n",
       "          0.20096041, -0.243635  ],\n",
       "        [-0.09166033,  0.17606586, -0.07725669, ..., -0.10304256,\n",
       "          0.02041118,  0.11113589],\n",
       "        ...,\n",
       "        [ 0.0405606 ,  0.03105868,  0.24855992, ..., -0.02338189,\n",
       "         -0.07242468, -0.01330239],\n",
       "        [ 0.19275856,  0.01228029,  0.16359009, ..., -0.12620077,\n",
       "         -0.1899295 ,  0.07836314],\n",
       "        [-0.09514332, -0.13801554,  0.05245879, ..., -0.07137573,\n",
       "         -0.31438267, -0.05649664]],\n",
       "\n",
       "       [[-0.21157132,  0.06224575, -0.16173288, ..., -0.21423268,\n",
       "         -0.12774879, -0.15862733],\n",
       "        [-0.07974929,  0.11040203,  0.02376164, ...,  0.26602677,\n",
       "          0.12222733, -0.30180264],\n",
       "        [-0.15838726,  0.02515485, -0.07299703, ..., -0.26734942,\n",
       "         -0.06252657,  0.03538641],\n",
       "        ...,\n",
       "        [ 0.17997538,  0.2174376 , -0.01656151, ..., -0.2121245 ,\n",
       "          0.06089866, -0.01283878],\n",
       "        [ 0.0557768 ,  0.10854049,  0.2367579 , ..., -0.0668644 ,\n",
       "         -0.01057936,  0.06431125],\n",
       "        [-0.00922295,  0.09675627, -0.00266632, ..., -0.1004072 ,\n",
       "         -0.10251202,  0.05085957]],\n",
       "\n",
       "       [[-0.08266047,  0.23557323, -0.01562801, ..., -0.05817087,\n",
       "         -0.23796213,  0.05267194],\n",
       "        [-0.07974929,  0.11040203,  0.02376164, ...,  0.26602677,\n",
       "          0.12222733, -0.30180264],\n",
       "        [-0.15838726,  0.02515485, -0.07299703, ..., -0.26734942,\n",
       "         -0.06252657,  0.03538641],\n",
       "        ...,\n",
       "        [ 0.05307978,  0.18589267,  0.24904794, ..., -0.0464561 ,\n",
       "          0.13895495,  0.1298237 ],\n",
       "        [ 0.13614967,  0.20831741,  0.18317716, ..., -0.15348816,\n",
       "         -0.02741955,  0.03666438],\n",
       "        [ 0.13919343, -0.14375813,  0.03462735, ..., -0.11715433,\n",
       "         -0.10774922, -0.05880013]]], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cardinalities = [3, 5, 10, 15, 20, 25, 30, 35]\n",
    "num_features = len(cardinalities)\n",
    "dim_token = 32\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=num_features, \n",
    "    n_informative=num_features, n_redundant=0, \n",
    "    n_repeated=0, n_classes=2, \n",
    "    n_clusters_per_class=2,\n",
    "    shuffle=True, random_state=123\n",
    ")\n",
    "\n",
    "# convert continuous to cat with quantils\n",
    "X_cat = np.concatenate([\n",
    "    np.digitize(X[:,i], bins=np.quantile(X[:,i], np.linspace(0,1,c+1))[1:-1])[...,np.newaxis]\n",
    "    for i, c in enumerate(cardinalities)\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "ne = CategoricalFeatureEmbedding(cardinalities=cardinalities,dim_token=dim_token)\n",
    "\n",
    "ne(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic MLP classification with CategoricalFeatureEmbedding "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c486376ded516fafe091783a6c70b600e9bfb5824ad41de96f5bf0836d62937"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
