{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : \n",
    "- como pasar al embedding que las categoricas de la misma columna son del mismo grupo(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models import build_tab_transformer, build_tab_transformer_v2, build_tab_transformer_v3\n",
    "\n",
    "from src.layers import CategoricalFeatureEmbedding, NumericalFeatureEmbedding, FeatureEmbedding, TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Dataset\n",
    "\n",
    "# https://epistasislab.github.io/\n",
    "from pmlb import fetch_data\n",
    "\n",
    "data = fetch_data('adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "target_column = 'target'\n",
    "categorical_features = data.drop(columns=[target_column]).select_dtypes(include=np.int64).columns.to_list()\n",
    "numeric_features = data.select_dtypes(include=np.float64).columns.to_list()\n",
    "\n",
    "features = data[numeric_features+categorical_features]\n",
    "target = data[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "categorical_transformer = OrdinalEncoder(dtype=np.int64,handle_unknown=\"use_encoded_value\",unknown_value=999)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    verbose_feature_names_out=True,\n",
    ")\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train_transformed,columns = [name.split(\"__\")[1] for name in preprocessor.get_feature_names_out()])\n",
    "X_test_df = pd.DataFrame(X_test_transformed,columns = [name.split(\"__\")[1] for name in preprocessor.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline_model(categories,num_continuous):\n",
    "    num_categories = len(categories)\n",
    "    cat_input = keras.layers.Input(shape=(num_categories,), name='cat_inputs')\n",
    "    num_input = keras.layers.Input(shape=(num_continuous,), name='num_inputs')\n",
    "    x=keras.layers.Dense(256, input_shape=(num_continuous,), activation='relu')(num_input)\n",
    "    x=keras.layers.Dense(128, input_shape=(num_continuous,), activation='relu')(x)\n",
    "    x=keras.layers.Dense(64, input_shape=(num_continuous,), activation='relu')(x)\n",
    "    x=keras.layers.Dense(32, activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=[num_input, cat_input], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "categories = preprocessor.transformers_[1][1].categories_\n",
    "categories = [len(c)+1 for c in categories]\n",
    "num_continuous = len(numeric_features)   \n",
    "\n",
    "# model = build_tab_transformer(categories,num_continuous, dim=32,\n",
    "#             dim_out=1, depth=6, heads=8, dense_dim=16, mlp_hidden_mults = (4, 2),\n",
    "#             mlp_act = keras.layers.ReLU(),attn_dropout = 0.1,ff_dropout = 0.1)\n",
    "\n",
    "# base_model = build_baseline_model(categories,num_continuous)\n",
    "\n",
    "modelv2 = build_tab_transformer_v2(categories,num_continuous, dim=32,\n",
    "            dim_out=1, depth=6, heads=8, ff_dim=16, mlp_hidden_mults = (4, 2),\n",
    "            mlp_act = keras.layers.ReLU(),attn_dropout = 0.1,ff_dropout = 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cat_inputs (InputLayer)        [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " categorical_feature_embedding   (None, 8, 32)       3488        ['cat_inputs[0][0]']             \n",
      " (CategoricalFeatureEmbedding)                                                                    \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 8, 32)       34768       ['categorical_feature_embedding[0\n",
      " erEncoder)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 8, 32)       34768       ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, 8, 32)       34768       ['transformer_encoder_1[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_3 (Transfo  (None, 8, 32)       34768       ['transformer_encoder_2[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_4 (Transfo  (None, 8, 32)       34768       ['transformer_encoder_3[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_5 (Transfo  (None, 8, 32)       34768       ['transformer_encoder_4[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " num_inputs (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_6 (Transfo  (None, 8, 32)       34768       ['transformer_encoder_5[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 6)           12          ['num_inputs[0][0]']             \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['transformer_encoder_6[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 262)          0           ['layer_normalization[0][0]',    \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " mlp (MLP)                      (None, 1)            41985       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambda)   (None, 1)            0           ['mlp[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 288,861\n",
      "Trainable params: 288,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(X_train.values)\n",
    "import tensorflow as tf\n",
    "\n",
    "def map_func(x,y):\n",
    "    return {'num_inputs': x[0],'cat_inputs': x[1]}, y\n",
    "    \n",
    "X_ds = tf.data.Dataset.from_tensor_slices((X_train[numeric_features].values, X_train[categorical_features].values))\n",
    "y_ds = tf.data.Dataset.from_tensor_slices(y_train.values)\n",
    "train_ds = tf.data.Dataset.zip((X_ds, y_ds))\n",
    "\n",
    "X_val_ds = tf.data.Dataset.from_tensor_slices((X_test[numeric_features].values,X_test[categorical_features].values))\n",
    "y_val_ds = tf.data.Dataset.from_tensor_slices(y_test.values)\n",
    "val_ds = tf.data.Dataset.zip((X_val_ds, y_val_ds))\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = train_ds.map(map_func).batch(batch_size)\n",
    "val_ds = val_ds.map(map_func).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compile_and_fit_model(model, train_ds, val_ds, epochs=1, lr=1e-4):\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = []\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop_callback = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5\n",
    "    )\n",
    "    callbacks = [early_stop_callback]\n",
    "\n",
    "    metrics = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.Accuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks, metrics=metrics)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "153/153 [==============================] - 54s 307ms/step - loss: 0.3838 - accuracy: 0.8220 - val_loss: 0.3614 - val_accuracy: 0.8318\n",
      "Epoch 2/40\n",
      "153/153 [==============================] - 51s 336ms/step - loss: 0.3626 - accuracy: 0.8298 - val_loss: 0.3570 - val_accuracy: 0.8320\n",
      "Epoch 3/40\n",
      "153/153 [==============================] - 48s 316ms/step - loss: 0.3582 - accuracy: 0.8330 - val_loss: 0.3552 - val_accuracy: 0.8329\n",
      "Epoch 4/40\n",
      "153/153 [==============================] - 50s 326ms/step - loss: 0.3564 - accuracy: 0.8336 - val_loss: 0.3549 - val_accuracy: 0.8337\n",
      "Epoch 5/40\n",
      "153/153 [==============================] - 59s 383ms/step - loss: 0.3553 - accuracy: 0.8334 - val_loss: 0.3514 - val_accuracy: 0.8358\n",
      "Epoch 6/40\n",
      "153/153 [==============================] - 62s 409ms/step - loss: 0.3524 - accuracy: 0.8353 - val_loss: 0.3509 - val_accuracy: 0.8374\n",
      "Epoch 7/40\n",
      "153/153 [==============================] - 53s 348ms/step - loss: 0.3508 - accuracy: 0.8361 - val_loss: 0.3497 - val_accuracy: 0.8368\n",
      "Epoch 8/40\n",
      "153/153 [==============================] - 51s 332ms/step - loss: 0.3492 - accuracy: 0.8359 - val_loss: 0.3490 - val_accuracy: 0.8367\n",
      "Epoch 9/40\n",
      "153/153 [==============================] - 48s 317ms/step - loss: 0.3470 - accuracy: 0.8373 - val_loss: 0.3481 - val_accuracy: 0.8360\n",
      "Epoch 10/40\n",
      "153/153 [==============================] - 49s 318ms/step - loss: 0.3452 - accuracy: 0.8380 - val_loss: 0.3485 - val_accuracy: 0.8378\n",
      "Epoch 11/40\n",
      "153/153 [==============================] - 48s 313ms/step - loss: 0.3443 - accuracy: 0.8386 - val_loss: 0.3471 - val_accuracy: 0.8376\n",
      "Epoch 12/40\n",
      "153/153 [==============================] - 45s 294ms/step - loss: 0.3429 - accuracy: 0.8398 - val_loss: 0.3459 - val_accuracy: 0.8386\n",
      "Epoch 13/40\n",
      "153/153 [==============================] - 52s 340ms/step - loss: 0.3421 - accuracy: 0.8404 - val_loss: 0.3463 - val_accuracy: 0.8383\n",
      "Epoch 14/40\n",
      "153/153 [==============================] - 53s 344ms/step - loss: 0.3409 - accuracy: 0.8407 - val_loss: 0.3444 - val_accuracy: 0.8397\n",
      "Epoch 15/40\n",
      "153/153 [==============================] - 48s 312ms/step - loss: 0.3398 - accuracy: 0.8412 - val_loss: 0.3443 - val_accuracy: 0.8402\n",
      "Epoch 16/40\n",
      "153/153 [==============================] - 50s 325ms/step - loss: 0.3379 - accuracy: 0.8428 - val_loss: 0.3441 - val_accuracy: 0.8405\n",
      "Epoch 17/40\n",
      "153/153 [==============================] - 53s 347ms/step - loss: 0.3378 - accuracy: 0.8424 - val_loss: 0.3452 - val_accuracy: 0.8404\n",
      "Epoch 18/40\n",
      "153/153 [==============================] - 48s 313ms/step - loss: 0.3373 - accuracy: 0.8433 - val_loss: 0.3439 - val_accuracy: 0.8392\n",
      "Epoch 19/40\n",
      "153/153 [==============================] - 58s 379ms/step - loss: 0.3355 - accuracy: 0.8445 - val_loss: 0.3455 - val_accuracy: 0.8400\n",
      "Epoch 20/40\n",
      "153/153 [==============================] - 49s 317ms/step - loss: 0.3358 - accuracy: 0.8439 - val_loss: 0.3464 - val_accuracy: 0.8413\n",
      "Epoch 21/40\n",
      "153/153 [==============================] - 46s 299ms/step - loss: 0.3352 - accuracy: 0.8443 - val_loss: 0.3426 - val_accuracy: 0.8413\n",
      "Epoch 22/40\n",
      "153/153 [==============================] - 50s 326ms/step - loss: 0.3332 - accuracy: 0.8452 - val_loss: 0.3443 - val_accuracy: 0.8413\n",
      "Epoch 23/40\n",
      "153/153 [==============================] - 47s 307ms/step - loss: 0.3333 - accuracy: 0.8454 - val_loss: 0.3458 - val_accuracy: 0.8416\n",
      "Epoch 24/40\n",
      "153/153 [==============================] - 45s 296ms/step - loss: 0.3331 - accuracy: 0.8459 - val_loss: 0.3441 - val_accuracy: 0.8417\n",
      "Epoch 25/40\n",
      "153/153 [==============================] - 42s 276ms/step - loss: 0.3319 - accuracy: 0.8463 - val_loss: 0.3443 - val_accuracy: 0.8401\n",
      "Epoch 26/40\n",
      "153/153 [==============================] - 42s 277ms/step - loss: 0.3314 - accuracy: 0.8459 - val_loss: 0.3458 - val_accuracy: 0.8392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f14d7376d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_and_fit_model(modelv2, train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D758130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D78EE50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D7A45B0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D80F2B0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D7C3F10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D852F40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F14D8B2D00>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_1_layer_call_fn while saving (showing 5 of 142). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tab-transformer-v2-21_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tab-transformer-v2-21_epochs\\assets\n"
     ]
    }
   ],
   "source": [
    "modelv2.save(\"../models/tab-transformer-v2-21_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "153/153 [==============================] - 52s 293ms/step - loss: 1.0131 - accuracy: 0.4186 - val_loss: 0.5715 - val_accuracy: 0.7654\n",
      "Epoch 2/40\n",
      "153/153 [==============================] - 49s 323ms/step - loss: 0.5483 - accuracy: 0.7559 - val_loss: 0.4913 - val_accuracy: 0.7680\n",
      "Epoch 3/40\n",
      "153/153 [==============================] - 46s 299ms/step - loss: 0.4871 - accuracy: 0.7689 - val_loss: 0.4340 - val_accuracy: 0.7919\n",
      "Epoch 4/40\n",
      "153/153 [==============================] - 48s 316ms/step - loss: 0.4511 - accuracy: 0.7853 - val_loss: 0.4120 - val_accuracy: 0.8136\n",
      "Epoch 5/40\n",
      "153/153 [==============================] - 50s 328ms/step - loss: 0.4312 - accuracy: 0.7981 - val_loss: 0.4018 - val_accuracy: 0.8165\n",
      "Epoch 6/40\n",
      "153/153 [==============================] - 45s 297ms/step - loss: 0.4200 - accuracy: 0.8042 - val_loss: 0.3955 - val_accuracy: 0.8175\n",
      "Epoch 7/40\n",
      "153/153 [==============================] - 47s 307ms/step - loss: 0.4133 - accuracy: 0.8070 - val_loss: 0.3917 - val_accuracy: 0.8205\n",
      "Epoch 8/40\n",
      "153/153 [==============================] - 47s 310ms/step - loss: 0.4065 - accuracy: 0.8120 - val_loss: 0.3887 - val_accuracy: 0.8210\n",
      "Epoch 9/40\n",
      "153/153 [==============================] - 48s 314ms/step - loss: 0.4027 - accuracy: 0.8132 - val_loss: 0.3862 - val_accuracy: 0.8210\n",
      "Epoch 10/40\n",
      "153/153 [==============================] - 44s 285ms/step - loss: 0.3979 - accuracy: 0.8154 - val_loss: 0.3834 - val_accuracy: 0.8206\n",
      "Epoch 11/40\n",
      "153/153 [==============================] - 44s 288ms/step - loss: 0.3957 - accuracy: 0.8158 - val_loss: 0.3808 - val_accuracy: 0.8217\n",
      "Epoch 12/40\n",
      "153/153 [==============================] - 45s 293ms/step - loss: 0.3936 - accuracy: 0.8156 - val_loss: 0.3789 - val_accuracy: 0.8241\n",
      "Epoch 13/40\n",
      "153/153 [==============================] - 44s 290ms/step - loss: 0.3900 - accuracy: 0.8197 - val_loss: 0.3768 - val_accuracy: 0.8238\n",
      "Epoch 14/40\n",
      "153/153 [==============================] - 44s 290ms/step - loss: 0.3899 - accuracy: 0.8164 - val_loss: 0.3749 - val_accuracy: 0.8259\n",
      "Epoch 15/40\n",
      "153/153 [==============================] - 45s 291ms/step - loss: 0.3864 - accuracy: 0.8189 - val_loss: 0.3733 - val_accuracy: 0.8261\n",
      "Epoch 16/40\n",
      "153/153 [==============================] - 44s 290ms/step - loss: 0.3844 - accuracy: 0.8213 - val_loss: 0.3719 - val_accuracy: 0.8274\n",
      "Epoch 17/40\n",
      "153/153 [==============================] - 44s 287ms/step - loss: 0.3823 - accuracy: 0.8217 - val_loss: 0.3710 - val_accuracy: 0.8280\n",
      "Epoch 18/40\n",
      "153/153 [==============================] - 43s 283ms/step - loss: 0.3811 - accuracy: 0.8221 - val_loss: 0.3699 - val_accuracy: 0.8300\n",
      "Epoch 19/40\n",
      "153/153 [==============================] - 45s 292ms/step - loss: 0.3791 - accuracy: 0.8235 - val_loss: 0.3689 - val_accuracy: 0.8295\n",
      "Epoch 20/40\n",
      "153/153 [==============================] - 46s 300ms/step - loss: 0.3787 - accuracy: 0.8233 - val_loss: 0.3674 - val_accuracy: 0.8304\n",
      "Epoch 21/40\n",
      "153/153 [==============================] - 50s 325ms/step - loss: 0.3780 - accuracy: 0.8230 - val_loss: 0.3668 - val_accuracy: 0.8311\n",
      "Epoch 22/40\n",
      "153/153 [==============================] - 50s 326ms/step - loss: 0.3766 - accuracy: 0.8245 - val_loss: 0.3662 - val_accuracy: 0.8314\n",
      "Epoch 23/40\n",
      "153/153 [==============================] - 48s 315ms/step - loss: 0.3758 - accuracy: 0.8235 - val_loss: 0.3659 - val_accuracy: 0.8307\n",
      "Epoch 24/40\n",
      "153/153 [==============================] - 44s 291ms/step - loss: 0.3754 - accuracy: 0.8256 - val_loss: 0.3651 - val_accuracy: 0.8307\n",
      "Epoch 25/40\n",
      "153/153 [==============================] - 45s 293ms/step - loss: 0.3747 - accuracy: 0.8238 - val_loss: 0.3648 - val_accuracy: 0.8312\n",
      "Epoch 26/40\n",
      "153/153 [==============================] - 44s 288ms/step - loss: 0.3743 - accuracy: 0.8258 - val_loss: 0.3639 - val_accuracy: 0.8305\n",
      "Epoch 27/40\n",
      "153/153 [==============================] - 43s 284ms/step - loss: 0.3729 - accuracy: 0.8239 - val_loss: 0.3636 - val_accuracy: 0.8308\n",
      "Epoch 28/40\n",
      "153/153 [==============================] - 44s 287ms/step - loss: 0.3717 - accuracy: 0.8257 - val_loss: 0.3631 - val_accuracy: 0.8317\n",
      "Epoch 29/40\n",
      "153/153 [==============================] - 44s 287ms/step - loss: 0.3715 - accuracy: 0.8258 - val_loss: 0.3628 - val_accuracy: 0.8316\n",
      "Epoch 30/40\n",
      "153/153 [==============================] - 47s 305ms/step - loss: 0.3706 - accuracy: 0.8265 - val_loss: 0.3624 - val_accuracy: 0.8322\n",
      "Epoch 31/40\n",
      "153/153 [==============================] - 47s 306ms/step - loss: 0.3710 - accuracy: 0.8264 - val_loss: 0.3620 - val_accuracy: 0.8318\n",
      "Epoch 32/40\n",
      "153/153 [==============================] - 48s 310ms/step - loss: 0.3693 - accuracy: 0.8280 - val_loss: 0.3617 - val_accuracy: 0.8317\n",
      "Epoch 33/40\n",
      "153/153 [==============================] - 50s 324ms/step - loss: 0.3688 - accuracy: 0.8281 - val_loss: 0.3616 - val_accuracy: 0.8310\n",
      "Epoch 34/40\n",
      "153/153 [==============================] - 49s 323ms/step - loss: 0.3681 - accuracy: 0.8281 - val_loss: 0.3612 - val_accuracy: 0.8304\n",
      "Epoch 35/40\n",
      "153/153 [==============================] - 50s 326ms/step - loss: 0.3692 - accuracy: 0.8279 - val_loss: 0.3607 - val_accuracy: 0.8311\n",
      "Epoch 36/40\n",
      "153/153 [==============================] - 44s 289ms/step - loss: 0.3683 - accuracy: 0.8276 - val_loss: 0.3603 - val_accuracy: 0.8314\n",
      "Epoch 37/40\n",
      "153/153 [==============================] - 45s 297ms/step - loss: 0.3674 - accuracy: 0.8283 - val_loss: 0.3607 - val_accuracy: 0.8309\n",
      "Epoch 38/40\n",
      "153/153 [==============================] - 48s 311ms/step - loss: 0.3687 - accuracy: 0.8270 - val_loss: 0.3603 - val_accuracy: 0.8319\n",
      "Epoch 39/40\n",
      "153/153 [==============================] - 47s 304ms/step - loss: 0.3674 - accuracy: 0.8286 - val_loss: 0.3600 - val_accuracy: 0.8313\n",
      "Epoch 40/40\n",
      "153/153 [==============================] - 48s 315ms/step - loss: 0.3666 - accuracy: 0.8281 - val_loss: 0.3600 - val_accuracy: 0.8312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1948275ff40>"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-5, decay=1e-3 / 200)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stop_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=40, callbacks=[early_stop_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_1_layer_call_fn, layer_normalization_1_layer_call_and_return_conditional_losses, layer_normalization_2_layer_call_fn while saving (showing 5 of 154). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tab-transformer-40_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tab-transformer-40_epochs\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/tab-transformer-40_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('../models/tab-transformer-40_epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 6s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09662233],\n",
       "       [0.7259842 ],\n",
       "       [0.6931739 ],\n",
       "       ...,\n",
       "       [0.71905434],\n",
       "       [0.9878825 ],\n",
       "       [0.9762927 ]], dtype=float32)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base_preds = base_model.predict(x=[X_test[numeric_features].values,X_test[categorical_features].values])\n",
    "\n",
    "loaded_model.predict(x=[X_test[numeric_features].values,X_test[categorical_features].values])\n",
    "\n",
    "# preds = model(inputs=[X_test[numeric_features].values,X_test[categorical_features].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(base_preds)\n",
    "# plt.show()\n",
    "\n",
    "base_preds[base_preds==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', 'd', 'z', 'c', 'b', 'a']"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
    "layer = tf.keras.layers.StringLookup()\n",
    "layer.adapt(data)\n",
    "layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer(data)\n",
    "\n",
    "df_cat_std = X_train[categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitos\\AppData\\Local\\Temp\\ipykernel_56996\\1244474346.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat_std.loc[:,col]=df_cat_std.loc[:,col].apply(lambda x: col+\"_\"+str(x))\n"
     ]
    }
   ],
   "source": [
    "for col in df_cat_std.columns:\n",
    "    df_cat_std.loc[:,col]=df_cat_std.loc[:,col].apply(lambda x: col+\"_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " 'native-country_39',\n",
       " 'race_4',\n",
       " 'workclass_4',\n",
       " 'sex_1',\n",
       " 'marital-status_2',\n",
       " 'relationship_0',\n",
       " 'sex_0',\n",
       " 'marital-status_4',\n",
       " 'education_11',\n",
       " 'relationship_1',\n",
       " 'education_15',\n",
       " 'education_9',\n",
       " 'relationship_3',\n",
       " 'marital-status_0',\n",
       " 'occupation_10',\n",
       " 'occupation_3',\n",
       " 'occupation_4',\n",
       " 'occupation_1',\n",
       " 'occupation_12',\n",
       " 'relationship_4',\n",
       " 'occupation_8',\n",
       " 'race_2',\n",
       " 'workclass_6',\n",
       " 'workclass_2',\n",
       " 'occupation_7',\n",
       " 'occupation_0',\n",
       " 'workclass_0',\n",
       " 'education_12',\n",
       " 'occupation_14',\n",
       " 'relationship_5',\n",
       " 'occupation_6',\n",
       " 'education_8',\n",
       " 'workclass_7',\n",
       " 'education_1',\n",
       " 'workclass_5',\n",
       " 'education_7',\n",
       " 'marital-status_5',\n",
       " 'marital-status_6',\n",
       " 'race_1',\n",
       " 'relationship_2',\n",
       " 'occupation_5',\n",
       " 'occupation_13',\n",
       " 'workclass_1',\n",
       " 'education_0',\n",
       " 'occupation_11',\n",
       " 'education_5',\n",
       " 'native-country_26',\n",
       " 'native-country_0',\n",
       " 'education_14',\n",
       " 'education_6',\n",
       " 'education_2',\n",
       " 'marital-status_3',\n",
       " 'education_10',\n",
       " 'education_4',\n",
       " 'race_0',\n",
       " 'race_3',\n",
       " 'native-country_30',\n",
       " 'education_3',\n",
       " 'occupation_9',\n",
       " 'native-country_11',\n",
       " 'native-country_33',\n",
       " 'native-country_2',\n",
       " 'native-country_19',\n",
       " 'native-country_8',\n",
       " 'native-country_9',\n",
       " 'native-country_5',\n",
       " 'native-country_3',\n",
       " 'native-country_35',\n",
       " 'native-country_22',\n",
       " 'native-country_6',\n",
       " 'native-country_23',\n",
       " 'native-country_13',\n",
       " 'native-country_40',\n",
       " 'native-country_31',\n",
       " 'native-country_24',\n",
       " 'education_13',\n",
       " 'native-country_4',\n",
       " 'native-country_14',\n",
       " 'native-country_32',\n",
       " 'native-country_36',\n",
       " 'native-country_27',\n",
       " 'native-country_20',\n",
       " 'native-country_12',\n",
       " 'native-country_29',\n",
       " 'native-country_7',\n",
       " 'native-country_10',\n",
       " 'marital-status_1',\n",
       " 'native-country_21',\n",
       " 'native-country_1',\n",
       " 'native-country_37',\n",
       " 'native-country_38',\n",
       " 'native-country_17',\n",
       " 'native-country_34',\n",
       " 'native-country_28',\n",
       " 'native-country_25',\n",
       " 'workclass_8',\n",
       " 'native-country_16',\n",
       " 'native-country_41',\n",
       " 'native-country_18',\n",
       " 'occupation_2',\n",
       " 'workclass_3',\n",
       " 'native-country_15']"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = df_cat_std.values\n",
    "layer = tf.keras.layers.StringLookup()\n",
    "layer.adapt(data)\n",
    "layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 3 34  8 19 13  2  7  1]\n",
      " [ 3  9  5 18 30  2  7  1]\n",
      " [27 12  5 26  6  2  4  1]], shape=(3, 8), dtype=int64)\n",
      "[['workclass_4' 'education_1' 'marital-status_4' 'occupation_12'\n",
      "  'relationship_3' 'race_4' 'sex_0' 'native-country_39']\n",
      " ['workclass_4' 'education_11' 'marital-status_2' 'occupation_1'\n",
      "  'relationship_5' 'race_4' 'sex_0' 'native-country_39']\n",
      " ['workclass_0' 'education_9' 'marital-status_2' 'occupation_0'\n",
      "  'relationship_0' 'race_4' 'sex_1' 'native-country_39']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(layer(data[:3]))\n",
    "print(data[:3])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c486376ded516fafe091783a6c70b600e9bfb5824ad41de96f5bf0836d62937"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
